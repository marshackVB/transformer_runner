---
# See https://huggingface.co/transformers/pretrained_models.html for a list of available models
# Most of the below parameters are explained in the docs here, https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments

model_type: "distilbert-base-uncased"

experiment_location: "/Shared/transformer_experiments/classification_experiments"

database_name: "default"
train_table_name: "fake_news_parquet_small_train"
test_table_name: "fake_news_parquet_small_test"
feature_col: "title_text"
label_col: "label"
num_labels: 2

streaming_read: True

# If set to -1, truncation will default to the model's maximum length.
max_token_length: 100 
batch_size: 32
num_train_epochs: 1

save_total_limit: 10
metric_for_best_model: 'f1'
seed: 123

